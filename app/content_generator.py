"""YouTubeã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import json
import re
from typing import Optional, Dict

import google.generativeai as genai

from app.config import config
from app.logging_utils import log_info, log_warning, log_error


def _extract_json_from_content(content: str) -> Dict:
    """
    Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰å …ç‰¢ã«JSONã‚’æŠ½å‡ºã—ã¦ãƒ‘ãƒ¼ã‚¹

    Args:
        content: Geminiãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        ãƒ‘ãƒ¼ã‚¹ã•ã‚ŒãŸJSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ

    Raises:
        json.JSONDecodeError: JSONæŠ½å‡ºãƒ»ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ãŸå ´åˆ
        ValueError: æœ‰åŠ¹ãªJSONãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
    """
    original_content = content

    # 1. ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’é™¤å»
    if "```json" in content:
        parts = content.split("```json")
        if len(parts) > 1:
            content = parts[1].split("```")[0].strip()
    elif "```" in content:
        parts = content.split("```")
        if len(parts) > 1:
            content = parts[1].split("```")[0].strip()

    # 2. JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ­£è¦è¡¨ç¾ã§æŠ½å‡º
    # ã¾ãšå®Œå…¨ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’æ¢ã™
    complete_obj_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', content, re.DOTALL)
    if complete_obj_match:
        content = complete_obj_match.group()
    else:
        # ä¸å®Œå…¨ãªã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚‚æ¢ã™
        incomplete_obj_match = re.search(r'\{.*', content, re.DOTALL)
        if incomplete_obj_match:
            content = incomplete_obj_match.group()
            # ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’å¼·åˆ¶çš„ã«é–‰ã˜ã‚‹
            if not content.rstrip().endswith('}'):
                content = content.rstrip().rstrip(',') + '}'
        else:
            raise ValueError(f"No JSON object found in response. Content: {original_content[:200]}")

    # 3. ã‚ˆãã‚ã‚‹å•é¡Œã‚’ä¿®æ­£
    # - æœ«å°¾ã®ã‚«ãƒ³ãƒã‚’å‰Šé™¤
    content = re.sub(r',\s*}', '}', content)
    content = re.sub(r',\s*\]', ']', content)
    # - ä¸å®Œå…¨ãªæ–‡å­—åˆ—ã‚’é–‰ã˜ã‚‹ (ä¾‹: "title": "è£æ–¹ã§é‡‘æŒã¡ã¯ç„¡ç†} -> "title": "è£æ–¹ã§é‡‘æŒã¡ã¯ç„¡ç†"})
    content = re.sub(r':\s*"([^"]*?)([}\]])' , r': "\1"\2', content)
    # - ä¸å®Œå…¨ãªã‚­ãƒ¼:å€¤ã®ãƒšã‚¢ã‚’ä¿®æ­£ï¼ˆå€¤ãŒãªã„å ´åˆï¼‰
    content = re.sub(r':\s*([,}])', r': ""\1', content)

    try:
        parsed = json.loads(content)
        log_info(f"Successfully parsed JSON: {list(parsed.keys())}")
        return parsed
    except json.JSONDecodeError as e:
        # ãƒ‡ãƒãƒƒã‚°ç”¨ã«å•é¡Œç®‡æ‰€ã‚’è¡¨ç¤º
        error_line = content.split('\n')[e.lineno - 1] if e.lineno <= len(content.split('\n')) else ""
        log_error(
            f"JSON parse failed at line {e.lineno}, col {e.colno}: {e.msg}\n"
            f"Error line: {error_line[:100]}\n"
            f"Full JSON content:\n{content}"
        )
        raise


def generate_title_and_description(
    transcript_text: str,
    source_url: Optional[str] = None,
    fallback_title: str = "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»"
) -> Dict[str, str]:
    """
    Gemini APIã‚’ä½¿ã£ã¦ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆ

    Args:
        transcript_text: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
        source_url: å…ƒå‹•ç”»ã®URLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        fallback_title: APIãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«

    Returns:
        {"title": "ã‚¿ã‚¤ãƒˆãƒ«", "description": "èª¬æ˜æ–‡"}
    """

    # Gemini APIãŒä½¿ãˆã‚‹å ´åˆã¯AIç”Ÿæˆ
    if config.GEMINI_API_KEY:
        try:
            return _generate_with_gemini(transcript_text, source_url, fallback_title)
        except Exception as e:
            log_warning(f"Gemini API failed, using fallback: {e}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç”Ÿæˆ
    return _generate_fallback(transcript_text, source_url, fallback_title)


def _generate_with_gemini(transcript_text: str, source_url: Optional[str], fallback_title: str) -> Dict[str, str]:
    """Gemini APIã§ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""

    log_info("Generating title and description with Gemini API")

    genai.configure(api_key=config.GEMINI_API_KEY)
    model = genai.GenerativeModel(config.GEMINI_MODEL)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«20æ–‡å­—ä»¥å†…ãƒ»ãƒã‚¤ãƒ³ãƒˆ20æ–‡å­—ä»¥å†…ã‚’æ˜ç¤ºï¼‰
    prompt = f"""ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€YouTube Shortsç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ–‡å­—èµ·ã“ã—ã€‘
{transcript_text[:1000]}

ã€è¦ä»¶ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: æ—¥æœ¬èªã§20æ–‡å­—ä»¥å†…ã€‚å‹•ç”»ã®ãƒ†ãƒ¼ãƒã‚„å•é¡Œæèµ·ã‚’ã™ã‚‹çŸ­ã„ãƒ•ãƒƒã‚¯ã€‚
  * ä¾‹: ã€Œç†æƒ³ã®ãƒ©ã‚¤ãƒ–ãƒã‚¦ã‚¹ã€ã€Œãƒãƒ³ãƒ‰ãƒãƒ³ãŒä¼æ¥­ã§å¤±æ•—ã™ã‚‹ç†ç”±ã€ã€Œã‚®ã‚¿ãƒ¼VSãƒ™ãƒ¼ã‚¹ã€
  * ç–‘å•å½¢ã‚„å¯¾æ¯”å½¢å¼ã‚‚åŠ¹æœçš„
  è¨˜å·ã®ä¹±ç”¨ã¯é¿ã‘ã€è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã«ã™ã‚‹ã“ã¨ã€‚

- èª¬æ˜æ–‡: 1è¡Œç›®ã«å‹•ç”»ã®å…·ä½“çš„ãªå†…å®¹ã‚„æ°—ã«ãªã‚‹ç­”ãˆã‚’20æ–‡å­—ä»¥å†…ã§æ›¸ãã€‚ã‚¿ã‚¤ãƒˆãƒ«ã¨ã¯ç•°ãªã‚‹å†…å®¹ã«ã™ã‚‹ã“ã¨ã€‚
  * ã‚¿ã‚¤ãƒˆãƒ«ã«å¯¾ã™ã‚‹ç­”ãˆã‚„å…·ä½“çš„ãªå†…å®¹ã‚’æ›¸ã
  * ä¾‹: ã€Œåº—é•·ãŒâ—¯â—ã‚’åˆ‡ã£ã¦ã„ã‚‹ã€ã€Œã‚¨ãƒ­ã„ã‹ã‚‰ã€ã€Œãã‚Œãã‚Œã«å‘ã„ã¦ã„ã‚‹äººé–“æ€§ã¯ï¼Ÿã€ã€Œè£æŠ€ã€ã‚«ãƒ©ã‚ªã‚±ç·¨ã€‘ã€
  * è¦–è´è€…ãŒã€Œãˆï¼Ÿã©ã†ã„ã†ã“ã¨ï¼Ÿã€ã¨æ°—ã«ãªã‚‹è¡¨ç¾ã‚’ä½¿ã†
  * çµè«–ã‚’å®Œå…¨ã«ã¯æ˜ã‹ã•ãšã€æœŸå¾…ã‚’é«˜ã‚ã‚‹
  2è¡Œç›®ä»¥é™ã§ç°¡æ½”ãªè£œè¶³ã¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼ˆ#Shortså«ã‚€ï¼‰ã€‚

é‡è¦: ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã®1è¡Œç›®ã¯å¿…ãšç•°ãªã‚‹å†…å®¹ã«ã—ã¦ãã ã•ã„ã€‚ä¸Šä¸‹ã§å‹•ç”»ã®å†…å®¹ã‚’ç´¹ä»‹ã™ã‚‹å½¢ã«ã—ã¦ãã ã•ã„ã€‚

- JSONå½¢å¼ã§å›ç­”: {{"title": "ã‚¿ã‚¤ãƒˆãƒ«", "description": "èª¬æ˜æ–‡"}}

JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

    safety_settings = [
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_NONE"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_NONE"
        }
    ]

    response = model.generate_content(
        prompt,
        safety_settings=safety_settings,
        generation_config={
            "temperature": 0.7,
            "max_output_tokens": 500,  # 300ã‹ã‚‰500ã«å¢—ã‚„ã™
        }
    )

    content = response.text.strip()
    log_info(f"Gemini response: {content[:100]}...")

    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒçŸ­ã™ãã‚‹å ´åˆã¯è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
    if len(content) < 100:
        log_warning(f"Response too short ({len(content)} chars). Full content: {content}")
        log_warning(f"Response candidates: {response.candidates if hasattr(response, 'candidates') else 'N/A'}")
        if hasattr(response, 'prompt_feedback'):
            log_warning(f"Prompt feedback: {response.prompt_feedback}")

    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
    usage = response.usage_metadata
    input_tokens = usage.prompt_token_count if usage else 0
    output_tokens = usage.candidates_token_count if usage else 0
    total_tokens = input_tokens + output_tokens

    # Gemini 1.5 Flash ã®æ–™é‡‘ï¼ˆ2024å¹´10æœˆæ™‚ç‚¹ï¼‰
    # Input: $0.075 / 1M tokens, Output: $0.30 / 1M tokens
    # 1ãƒ‰ãƒ« = 150å††ã¨ä»®å®š
    INPUT_COST_PER_1M = 0.075 * 150  # 11.25å††
    OUTPUT_COST_PER_1M = 0.30 * 150  # 45å††

    input_cost_jpy = (input_tokens / 1_000_000) * INPUT_COST_PER_1M
    output_cost_jpy = (output_tokens / 1_000_000) * OUTPUT_COST_PER_1M
    total_cost_jpy = input_cost_jpy + output_cost_jpy

    log_info(f"Token usage: {input_tokens} input + {output_tokens} output = {total_tokens} total")
    log_info(f"Cost: Â¥{total_cost_jpy:.4f} (input: Â¥{input_cost_jpy:.4f}, output: Â¥{output_cost_jpy:.4f})")

    # JSONæŠ½å‡º - ã‚ˆã‚Šå …ç‰¢ãªæ–¹æ³•ã‚’ä½¿ç”¨
    try:
        result = _extract_json_from_content(content)
        title = result.get("title", "").strip()
        description = result.get("description", "").strip()

        # titleã¾ãŸã¯descriptionãŒç©ºã®å ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨
        if not title or not description:
            log_warning(f"Incomplete Gemini response (title: {bool(title)}, description: {bool(description)}), using fallback")
            fallback_result = _generate_fallback(transcript_text, source_url, fallback_title)

            # ç©ºã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§è£œå®Œ
            if not title:
                title = fallback_result["title"]
            if not description:
                description = fallback_result["description"]
        else:
            # å…ƒå‹•ç”»URLã‚’è¿½åŠ 
            if source_url:
                description += f"\n\nğŸ“Œ å…ƒå‹•ç”»: {source_url}"

            description += "\n\n#Shorts"

        log_info(f"Generated title: {title}")
        return {
            "title": title,
            "description": description,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "cost_jpy": total_cost_jpy
        }
    except Exception as e:
        log_error(f"JSON parsing failed: {e}")
        log_info(f"Full response content: {content}")
        raise ValueError(f"Failed to parse JSON from Gemini response: {e}") from e


def _generate_fallback(
    transcript_text: str,
    source_url: Optional[str],
    fallback_title: str
) -> Dict[str, str]:
    """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""

    log_info("Generating title and description with rule-based fallback")

    # è¤‡æ•°ã®æ–‡ã‚’æŠ½å‡º
    sentences = re.split(r"[ã€‚ï¼Ÿï¼\?]", transcript_text.strip()) if transcript_text else []
    sentences = [s.strip() for s in sentences if s.strip()]

    def _hookify(text: str, limit: int) -> str:
        t = text.strip()
        if t.endswith("ã‘ã©"):
            t = t[:-2] + "ï¼Ÿ"
        if t.endswith("ã‘ã©ã€"):
            t = t[:-3] + "ï¼Ÿ"
        # 2è¡Œè¡¨ç¤ºã«å¯¾å¿œã™ã‚‹ãŸã‚ã€limitã‚’è¶…ãˆã¦ã‚‚ã€Œâ€¦ã€ã‚’ä»˜ã‘ãªã„
        if len(t) > limit:
            t = t[:limit]
        return t or fallback_title

    def _create_teaser_point(text: str, limit: int = 20) -> str:
        """å‹•ç”»ã®ãƒã‚¤ãƒ³ãƒˆã‚’ã€Œâ—â—ã§ã„ã‚‹ã“ã¨ã€ã®ã‚ˆã†ãªä¼ã›å­—å½¢å¼ã§ä½œæˆ"""
        t = text.strip()

        # ã€Œ...ã€ã‚„ã€Œâ€¦ã€ã‚’é™¤å»ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        t_clean = t.replace('...', '').replace('â€¦', '').strip()

        # æ–‡æœ«ãŒã€Œã„ã‚‹ã“ã¨ã€ã€Œã™ã‚‹ã“ã¨ã€ã€Œãªã‚‹ã“ã¨ã€ãªã©ã®å ´åˆã€é‡è¦éƒ¨åˆ†ã‚’ä¼ã›å­—ã«
        patterns = [
            (r'(.+)(ã§ã„ã‚‹ã“ã¨|ã«ã„ã‚‹ã“ã¨)$', r'â—â—\2'),  # ã€Œã€‡ã€‡ã§ã„ã‚‹ã“ã¨ã€â†’ã€Œâ—â—ã§ã„ã‚‹ã“ã¨ã€
            (r'(.+)(ã§ã™ã‚‹ã“ã¨|ã«ã™ã‚‹ã“ã¨|ã‚’ã™ã‚‹ã“ã¨)$', r'â—â—\2'),  # ã€Œã€‡ã€‡ã™ã‚‹ã“ã¨ã€â†’ã€Œâ—â—ã™ã‚‹ã“ã¨ã€
            (r'(.+)(ã«ãªã‚‹ã“ã¨)$', r'â—â—\2'),  # ã€Œã€‡ã€‡ã«ãªã‚‹ã“ã¨ã€â†’ã€Œâ—â—ã«ãªã‚‹ã“ã¨ã€
            (r'(.+)(ãŒé‡è¦|ãŒå¤§äº‹|ãŒãƒã‚¤ãƒ³ãƒˆ)$', r'â—â—\2'),  # ã€Œã€‡ã€‡ãŒé‡è¦ã€â†’ã€Œâ—â—ãŒé‡è¦ã€
            (r'(.+)(ã§ã‚ã‚‹ã“ã¨|ã§ã‚ã‚‹ã“ã¨)$', r'â—â—\2'),  # ã€Œã€‡ã€‡ã§ã‚ã‚‹ã“ã¨ã€â†’ã€Œâ—â—ã§ã‚ã‚‹ã“ã¨ã€
        ]

        for pattern, replacement in patterns:
            match = re.search(pattern, t_clean)
            if match:
                result = re.sub(pattern, replacement, t_clean)
                # é•·ã•èª¿æ•´
                if len(result) > limit:
                    # æœ«å°¾ã‹ã‚‰é€†ç®—ã—ã¦limitæ–‡å­—ã«åã‚ã‚‹
                    result = 'â—â—' + result[-(limit-2):]
                return result + 'ï¼'

        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ãƒãƒƒãƒã—ãªã„å ´åˆã¯é€šå¸¸ã®hookify
        return _hookify(t, limit)

    # ã‚¿ã‚¤ãƒˆãƒ«: æœ€åˆã®æ–‡ã‚’ãƒ†ãƒ¼ãƒã¨ã—ã¦ä½¿ç”¨ï¼ˆ20æ–‡å­—ä»¥å†…ï¼‰
    first_sentence = sentences[0] if sentences else fallback_title
    title = _hookify(first_sentence.replace("\n", " "), 20)

    # ãƒã‚¤ãƒ³ãƒˆ: 2ç•ªç›®ã®æ–‡ã¾ãŸã¯æœ€åˆã®æ–‡ã®ç¶šãã‚’ä½¿ç”¨ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã¨ç•°ãªã‚‹å†…å®¹ã«ã™ã‚‹ï¼‰
    if len(sentences) > 1:
        second_sentence = sentences[1]
        point = _create_teaser_point(second_sentence.replace("\n", " "), 20)
    else:
        # 1æ–‡ã—ã‹ãªã„å ´åˆã¯ã€æ–‡ã®å¾ŒåŠéƒ¨åˆ†ã‚’ä½¿ã†
        words = first_sentence.split()
        if len(words) > 3:
            point = _create_teaser_point(" ".join(words[len(words)//2:]).replace("\n", " "), 20)
        else:
            point = _hookify("ç¶šãã‚’ãƒã‚§ãƒƒã‚¯ï¼", 20)
    description = point

    if source_url:
        description += f"\n\nğŸ“Œ å…ƒå‹•ç”»: {source_url}"

    description += "\n\n#Shorts"

    return {
        "title": title,
        "description": description,
        "input_tokens": 0,
        "output_tokens": 0,
        "total_tokens": 0,
        "cost_jpy": 0.0
    }
