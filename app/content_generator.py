"""YouTubeã‚¿ã‚¤ãƒˆãƒ«ãƒ»èª¬æ˜æ–‡ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import json
import re
from typing import Optional, Dict

import google.generativeai as genai

from app.config import config
from app.logging_utils import log_info, log_warning, log_error


def generate_title_and_description(
    transcript_text: str,
    source_url: Optional[str] = None,
    fallback_title: str = "ã‚·ãƒ§ãƒ¼ãƒˆå‹•ç”»"
) -> Dict[str, str]:
    """
    Gemini APIã‚’ä½¿ã£ã¦ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆ

    Args:
        transcript_text: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ–‡å­—èµ·ã“ã—ãƒ†ã‚­ã‚¹ãƒˆ
        source_url: å…ƒå‹•ç”»ã®URLï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        fallback_title: APIãŒä½¿ãˆãªã„å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¿ã‚¤ãƒˆãƒ«

    Returns:
        {"title": "ã‚¿ã‚¤ãƒˆãƒ«", "description": "èª¬æ˜æ–‡"}
    """

    # Gemini APIãŒä½¿ãˆã‚‹å ´åˆã¯AIç”Ÿæˆ
    if config.GEMINI_API_KEY:
        try:
            return _generate_with_gemini(transcript_text, source_url)
        except Exception as e:
            log_warning(f"Gemini API failed, using fallback: {e}")

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ç”Ÿæˆ
    return _generate_fallback(transcript_text, source_url, fallback_title)


def _generate_with_gemini(transcript_text: str, source_url: Optional[str]) -> Dict[str, str]:
    """Gemini APIã§ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆ"""

    log_info("Generating title and description with Gemini API")

    genai.configure(api_key=config.GEMINI_API_KEY)
    model = genai.GenerativeModel(config.GEMINI_MODEL)

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆï¼ˆã‚¿ã‚¤ãƒˆãƒ«8æ–‡å­—ä»¥å†…ãƒ»ãƒã‚¤ãƒ³ãƒˆ10æ–‡å­—ä»¥å†…ã‚’æ˜ç¤ºï¼‰
    prompt = f"""ä»¥ä¸‹ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€YouTube Shortsç”¨ã®ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

ã€æ–‡å­—èµ·ã“ã—ã€‘
{transcript_text[:1000]}

ã€è¦ä»¶ã€‘
- ã‚¿ã‚¤ãƒˆãƒ«: æ—¥æœ¬èªã§8æ–‡å­—ä»¥å†…ã€‚çŸ­ãå¼·ã„è¨€è‘‰ã§ç›®ã‚’å¼•ãã“ã¨ï¼ˆä¾‹:ã€Œæœ€å¼·ã®è£æŠ€ã€ã€Œ5ç§’ã§å³ç­”ã€ï¼‰ã€‚è¨˜å·ä¹±ç”¨ã¯é¿ã‘ã‚‹ã€‚
- èª¬æ˜æ–‡: 1è¡Œç›®ã«ã‚·ãƒ§ãƒ¼ãƒˆéƒ¨åˆ†ã®ãƒã‚¤ãƒ³ãƒˆã‚’10æ–‡å­—ä»¥å†…ã§æ›¸ãã€‚2è¡Œç›®ä»¥é™ã§ç°¡æ½”ãªè£œè¶³ã¨ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ï¼ˆ#Shortså«ã‚€ï¼‰ã€‚
- JSONå½¢å¼ã§å›ç­”: {{"title": "ã‚¿ã‚¤ãƒˆãƒ«", "description": "èª¬æ˜æ–‡"}}

JSONå½¢å¼ã®ã¿ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚"""

    response = model.generate_content(
        prompt,
        generation_config={
            "temperature": 0.7,
            "max_output_tokens": 300,
        }
    )

    content = response.text.strip()
    log_info(f"Gemini response: {content[:100]}...")

    # ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã¨ã‚³ã‚¹ãƒˆã‚’è¨ˆç®—
    usage = response.usage_metadata
    input_tokens = usage.prompt_token_count if usage else 0
    output_tokens = usage.candidates_token_count if usage else 0
    total_tokens = input_tokens + output_tokens

    # Gemini 1.5 Flash ã®æ–™é‡‘ï¼ˆ2024å¹´10æœˆæ™‚ç‚¹ï¼‰
    # Input: $0.075 / 1M tokens, Output: $0.30 / 1M tokens
    # 1ãƒ‰ãƒ« = 150å††ã¨ä»®å®š
    INPUT_COST_PER_1M = 0.075 * 150  # 11.25å††
    OUTPUT_COST_PER_1M = 0.30 * 150  # 45å††

    input_cost_jpy = (input_tokens / 1_000_000) * INPUT_COST_PER_1M
    output_cost_jpy = (output_tokens / 1_000_000) * OUTPUT_COST_PER_1M
    total_cost_jpy = input_cost_jpy + output_cost_jpy

    log_info(f"Token usage: {input_tokens} input + {output_tokens} output = {total_tokens} total")
    log_info(f"Cost: Â¥{total_cost_jpy:.4f} (input: Â¥{input_cost_jpy:.4f}, output: Â¥{output_cost_jpy:.4f})")

    # JSONæŠ½å‡º
    json_match = re.search(r'\{.*\}', content, re.DOTALL)
    if json_match:
        result = json.loads(json_match.group())
        title = result.get("title", "").strip()
        description = result.get("description", "").strip()

        # å…ƒå‹•ç”»URLã‚’è¿½åŠ 
        if source_url:
            description += f"\n\nğŸ“Œ å…ƒå‹•ç”»: {source_url}"

        description += "\n\n#Shorts"

        log_info(f"Generated title: {title}")
        return {
            "title": title,
            "description": description,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "total_tokens": total_tokens,
            "cost_jpy": total_cost_jpy
        }

    raise ValueError("Failed to parse JSON from Gemini response")


def _generate_fallback(
    transcript_text: str,
    source_url: Optional[str],
    fallback_title: str
) -> Dict[str, str]:
    """ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ã§ã‚¿ã‚¤ãƒˆãƒ«ã¨èª¬æ˜æ–‡ã‚’ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""

    log_info("Generating title and description with rule-based fallback")

    # å…ˆé ­æ–‡ã‚’æŠ½å‡º
    sentences = re.split(r"[ã€‚ï¼Ÿï¼\?]", transcript_text.strip()) if transcript_text else []
    first_sentence = (sentences[0].strip() if sentences and sentences[0].strip() else fallback_title).replace("\n", " ")

    def _hookify(text: str, limit: int) -> str:
        t = text.strip()
        if t.endswith("ã‘ã©"):
            t = t[:-2] + "ï¼Ÿ"
        if t.endswith("ã‘ã©ã€"):
            t = t[:-3] + "ï¼Ÿ"
        if len(t) > limit:
            t = t[: limit - 1] + "â€¦"
        return t or fallback_title

    # ã‚¿ã‚¤ãƒˆãƒ«: 12æ–‡å­—ä»¥å†…ã«å¼·åˆ¶
    title = _hookify(first_sentence, 12)

    # èª¬æ˜æ–‡: å…ˆé ­è¡Œã«18æ–‡å­—ã®ãƒã‚¤ãƒ³ãƒˆã‚’ç½®ã
    point = _hookify(first_sentence, 18)
    description = point

    if source_url:
        description += f"\n\nğŸ“Œ å…ƒå‹•ç”»: {source_url}"

    description += "\n\n#Shorts"

    return {
        "title": title,
        "description": description,
        "input_tokens": 0,
        "output_tokens": 0,
        "total_tokens": 0,
        "cost_jpy": 0.0
    }
